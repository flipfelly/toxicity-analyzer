{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b7d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o dataset...\n",
      "Dataset carregado com sucesso!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comentario</th>\n",
       "      <th>anotator1</th>\n",
       "      <th>anotator2</th>\n",
       "      <th>anotator3</th>\n",
       "      <th>label_final</th>\n",
       "      <th>links_post</th>\n",
       "      <th>account_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mais um lixo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Essa nao tem vergonha na cara!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Essa mulher √© doente.pilantra!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Comunista safada...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.instagram.com/p/B2uThqdH9xI/</td>\n",
       "      <td>Carla Zambelli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         comentario  anotator1  \\\n",
       "0   1                                       Mais um lixo          1   \n",
       "1   2                    Essa nao tem vergonha na cara!!          1   \n",
       "2   3                     Essa mulher √© doente.pilantra!          1   \n",
       "3   4                                Comunista safada...          1   \n",
       "4   5  Vagabunda. Comunista. Mentirosa. O povo chilen...          1   \n",
       "\n",
       "   anotator2  anotator3  label_final  \\\n",
       "0          1          1            1   \n",
       "1          1          1            1   \n",
       "2          1          1            1   \n",
       "3          1          1            1   \n",
       "4          1          1            1   \n",
       "\n",
       "                                 links_post    account_post  \n",
       "0  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "1  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "2  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "3  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  \n",
       "4  https://www.instagram.com/p/B2uThqdH9xI/  Carla Zambelli  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribui√ß√£o das classes:\n",
      "label_final\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Iniciando pr√©-processamento...\n",
      "Dados divididos: 5600 para treino, 1400 para teste.\n",
      "Vetorizando o texto...\n",
      "Treinando o modelo de classifica√ß√£o...\n",
      "Modelo treinado com sucesso!\n",
      "\n",
      "Avaliando o modelo nos dados de teste...\n",
      "\n",
      "Acur√°cia: 0.8314285714285714\n",
      "\n",
      "Relat√≥rio de Classifica√ß√£o:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  N√£o Odioso       0.83      0.83      0.83       700\n",
      "      Odioso       0.83      0.83      0.83       700\n",
      "\n",
      "    accuracy                           0.83      1400\n",
      "   macro avg       0.83      0.83      0.83      1400\n",
      "weighted avg       0.83      0.83      0.83      1400\n",
      "\n",
      "\n",
      "--- MVP PRONTO PARA USO ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# URL do dataset HateBR no GitHub\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/franciellevargas/HateBR/main/dataset/HateBR.csv'\n",
    "\n",
    "# 1. Carregar o dataset\n",
    "print(\"Carregando o dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_URL)\n",
    "    print(\"Dataset carregado com sucesso!\")\n",
    "    # Mostra as primeiras linhas e a distribui√ß√£o das classes\n",
    "    display(df.head())\n",
    "    print(\"\\nDistribui√ß√£o das classes:\")\n",
    "    print(df['label_final'].value_counts(normalize=True))\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Pr√©-processamento e Defini√ß√£o das vari√°veis\n",
    "print(\"\\nIniciando pr√©-processamento...\")\n",
    "# Para este MVP, a √∫nica limpeza ser√° converter para min√∫sculas.\n",
    "# O TfidfVectorizer j√° lida com muita coisa.\n",
    "X = df['comentario'].str.lower()\n",
    "y = df['label_final']\n",
    "\n",
    "# 3. Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Dados divididos: {len(X_train)} para treino, {len(X_test)} para teste.\")\n",
    "\n",
    "# 4. Vetoriza√ß√£o do texto usando TF-IDF\n",
    "print(\"Vetorizando o texto...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Usamos as 5000 palavras mais relevantes\n",
    "\n",
    "# Aprende o vocabul√°rio com os dados de treino e transforma os dados de treino\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Apenas transforma os dados de teste com o vocabul√°rio j√° aprendido\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# 5. Treinamento do modelo de Regress√£o Log√≠stica\n",
    "print(\"Treinando o modelo de classifica√ß√£o...\")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vect, y_train)\n",
    "print(\"Modelo treinado com sucesso!\")\n",
    "\n",
    "# 6. Avalia√ß√£o do modelo\n",
    "print(\"\\nAvaliando o modelo nos dados de teste...\")\n",
    "y_pred = model.predict(X_test_vect)\n",
    "\n",
    "print(\"\\nAcur√°cia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['N√£o Odioso', 'Odioso']))\n",
    "\n",
    "# Agora que o modelo est√° treinado, podemos us√°-lo.\n",
    "# Os objetos que precisamos salvar/usar para novas previs√µes s√£o:\n",
    "# - `model` (o classificador)\n",
    "# - `vectorizer` (o vetorizador)\n",
    "\n",
    "print(\"\\n--- MVP PRONTO PARA USO ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c96fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_toxicidade(comentario: str, model, vectorizer) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um coment√°rio e retorna a classifica√ß√£o de toxicidade\n",
    "    e a probabilidade de ser discurso de √≥dio.\n",
    "    \"\"\"\n",
    "    # 1. Aplicar o mesmo pr√©-processamento (min√∫sculas)\n",
    "    comentario_processado = comentario.lower()\n",
    "    \n",
    "    # 2. Vetorizar o coment√°rio usando o vetorizador J√Å TREINADO\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    \n",
    "    # 3. Fazer a predi√ß√£o\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    \n",
    "    # A probabilidade de ser discurso de √≥dio √© a probabilidade da classe \"1\"\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    if predicao[0] == 1:\n",
    "        classificacao = \"Discurso de √ìdio\"\n",
    "    else:\n",
    "        classificacao = \"N√£o √© Discurso de √ìdio\"\n",
    "        \n",
    "    return {\n",
    "        \"classificacao\": classificacao,\n",
    "        \"nivel_toxicidade\": f\"{prob_odio:.2%}\" # Formata como porcentagem\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e31c825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando o MVP com novos coment√°rios ---\n",
      "Coment√°rio: 'Esses pol√≠ticos s√£o todos uns bandidos, tinham que sumir do mapa!'\n",
      "Resultado: {'classificacao': 'Discurso de √ìdio', 'nivel_toxicidade': '88.81%'}\n",
      "\n",
      "Coment√°rio: 'O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.'\n",
      "Resultado: {'classificacao': 'N√£o √© Discurso de √ìdio', 'nivel_toxicidade': '35.20%'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- EXEMPLOS DE USO ---\n",
    "print(\"\\n--- Testando o MVP com novos coment√°rios ---\")\n",
    "\n",
    "# Exemplo 1: Coment√°rio potencialmente t√≥xico\n",
    "comentario1 = \"Esses pol√≠ticos s√£o todos uns bandidos, tinham que sumir do mapa!\"\n",
    "resultado1 = avaliar_toxicidade(comentario1, model, vectorizer)\n",
    "print(f\"Coment√°rio: '{comentario1}'\")\n",
    "print(f\"Resultado: {resultado1}\\n\")\n",
    "\n",
    "# Exemplo 2: Coment√°rio neutro\n",
    "comentario2 = \"O jogo de futebol ontem foi muito emocionante, gostei bastante do resultado.\"\n",
    "resultado2 = avaliar_toxicidade(comentario2, model, vectorizer)\n",
    "print(f\"Coment√°rio: '{comentario2}'\")\n",
    "print(f\"Resultado: {resultado2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2b927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando o modelo e o vetorizador em arquivos...\n",
      "Modelo e vetorizador salvos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# (Ap√≥s o bloco de treinamento e avalia√ß√£o do modelo...)\n",
    "import joblib\n",
    "\n",
    "print(\"\\nSalvando o modelo e o vetorizador em arquivos...\")\n",
    "\n",
    "# Salva o modelo treinado\n",
    "joblib.dump(model, 'modelo_odio.joblib')\n",
    "\n",
    "# Salva o vetorizador\n",
    "joblib.dump(vectorizer, 'vetorizador_odio.joblib')\n",
    "\n",
    "print(\"Modelo e vetorizador salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dff293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo e vetorizador carregados com sucesso.\n",
      "\n",
      "--- INICIANDO AN√ÅLISE DE TOXICIDADE NO REDDIT ---\n",
      "Conex√£o com a API do Reddit estabelecida. Modo Read-Only: True\n",
      "\n",
      "Buscando posts populares no r/brasil...\n",
      "Analisando coment√°rios do post: 'Arte de Laerte'\n",
      "\n",
      "--- Relat√≥rio Final da An√°lise ---\n",
      "  - Subreddit analisado: r/brasil\n",
      "  - Post: 'Arte de Laerte...'\n",
      "  - Coment√°rios analisados: 30\n",
      "  - Coment√°rios classificados como discurso de √≥dio: 14\n",
      "  - N√≠vel m√©dio de toxicidade nos coment√°rios: 49.63%\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Coment√°rios Classificados como Discurso de √ìdio ---\n",
      "1. o tra√ßo dela √© t√£o foda que ela desenha a coisa mais manjada e √≥bvia do mundo e eu ainda pago pau\n",
      "---\n",
      "2. #\"O crime est√° em todo lugar.... At√© dentro dessa casa.\"\n",
      "---\n",
      "3. Detalhe... Essa charge √© de Outubro de 2024... O Chupetinha veio a p√∫blico defender Fintech de PCC poucos meses depois. Todo mundo j√° sabia o que tava rolando.\n",
      "---\n",
      "4. Na √©poca a maior apreens√£o de fuzis no RJ foi no condom√≠nio do Bolsonaro.\n",
      "\n",
      "PM jagun√ßo do Caiado matou informante do PCC com 12 tiros.\n",
      "\n",
      "Deputado inventa fake news para evitar fiscaliza√ß√£o e facilitar lavagem de dinheiro do PCC.\n",
      "\n",
      "√â isso, trabalham para o crime. Um fuzil n√£o chega na m√£o de um fodido que mora em bairro sem esgoto atrav√©s de m√°gica.\n",
      "---\n",
      "5. Exatamente. \n",
      "\n",
      "Mas a PM nunca vai chacinar a farinha lima igual faz na favela‚Ä¶ pq ser√° n√©?\n",
      "---\n",
      "6. Essa ela fez f√°cil de entender kkkk\n",
      "---\n",
      "7. S√≥ faltou um bras√£o do estado ou uma plaquinha de deputado...\n",
      "---\n",
      "8. se chama crime organizado por um motivo\n",
      "---\n",
      "9. Matar ou roubar uma pessoa √© um crime, tem gente que vai querer a morte desses bandidos.\n",
      "\n",
      "Agora... matar ou roubar em escala... dai s√£o s√≥ neg√≥cios.\n",
      "---\n",
      "10. Essa Laerte √© muito esperta mas est√° perigosamente pr√≥xima de virar um Armandinho\n",
      "---\n",
      "11. Foda que essa tirinha ai tem anos kkkkk\n",
      "\n",
      "Edit: 1 Ano, Outubro de 2024\n",
      "---\n",
      "12. Mais uma pra lista: Adriano da N√≥brega, o milico do Bope que matou a Marielle Franco, foi encontrado escondido e foi morto no s√≠tio de um vereador do PL na Bahia, o partido do Bozo na √©poca. Nos dias anteriores √† morte, ele ligou para o advogado dele e disse que temia ser morto como queima de arquivo. O Adriano era amigo pr√≥ximo da fam√≠lia do Bozo, foi condecorado pelo Fl√°vio, a esposa e m√£e dele eram funcion√°rias fantasmas da fam√≠lia Bozo. Os policiais que mataram ele disseram que ele resistiu e houve troca de tiros, por√©m a aut√≥psia meses depois demonstrou que n√£o havia p√≥lvora nos dedos de Adriano no momento de sua morte, contradizendo a vers√£o da pol√≠cia.\n",
      "---\n",
      "13. Que mora no extremo sul da cidade de S√£o Paulo (Graja√∫, Parelheiros e Marsilac) \"n√£o\" sabe e \"nem\" viu nada sobre isso....\n",
      "---\n",
      "14. Envelheceu que nem vinho ent√£o kk\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# --- CONFIGURA√á√ÉO ---\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "\n",
    "# Carregar o modelo e o vetorizador salvos\n",
    "try:\n",
    "    model = joblib.load('modelo_odio.joblib')\n",
    "    vectorizer = joblib.load('vetorizador_odio.joblib')\n",
    "    print(\"Modelo e vetorizador carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivos 'modelo_odio.joblib' ou 'vetorizador_odio.joblib' n√£o encontrados.\")\n",
    "    print(\"Certifique-se de executar o script de treinamento ('analisador_odio.py') primeiro.\")\n",
    "    exit()\n",
    "\n",
    "# --- FUN√á√ïES ---\n",
    "\n",
    "def avaliar_toxicidade(comentario: str) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um coment√°rio e retorna a classifica√ß√£o de toxicidade\n",
    "    e a probabilidade de ser discurso de √≥dio.\n",
    "    \"\"\"\n",
    "    comentario_processado = comentario.lower()\n",
    "    comentario_vect = vectorizer.transform([comentario_processado])\n",
    "    predicao = model.predict(comentario_vect)\n",
    "    probabilidades = model.predict_proba(comentario_vect)\n",
    "    prob_odio = probabilidades[0][1]\n",
    "    \n",
    "    return {\n",
    "        \"eh_odio\": predicao[0] == 1,\n",
    "        \"nivel_toxicidade\": prob_odio\n",
    "    }\n",
    "\n",
    "# --- EXECU√á√ÉO PRINCIPAL ---\n",
    "\n",
    "def main():\n",
    "    print(\"\\n--- INICIANDO AN√ÅLISE DE TOXICIDADE NO REDDIT ---\")\n",
    "\n",
    "    # Conectar √† API do Reddit\n",
    "    try:\n",
    "        reddit = praw.Reddit(\n",
    "            client_id=CLIENT_ID,\n",
    "            client_secret=CLIENT_SECRET,\n",
    "            user_agent=USER_AGENT,\n",
    "            check_for_async=False\n",
    "        )\n",
    "        print(f\"Conex√£o com a API do Reddit estabelecida. Modo Read-Only: {reddit.read_only}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar com a API do Reddit: {e}\")\n",
    "        return\n",
    "\n",
    "    subreddit_alvo = \"brasil\"\n",
    "    limite_comentarios = 100\n",
    "\n",
    "    print(f\"\\nBuscando posts populares no r/{subreddit_alvo}...\")\n",
    "    \n",
    "    subreddit = reddit.subreddit(subreddit_alvo)\n",
    "    try:\n",
    "        post_popular = next(p for p in subreddit.hot(limit=5) if not p.stickied)\n",
    "        print(f\"Analisando coment√°rios do post: '{post_popular.title}'\")\n",
    "    except StopIteration:\n",
    "        print(f\"N√£o foi poss√≠vel encontrar um post v√°lido no r/{subreddit_alvo}.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao buscar o post: {e}\")\n",
    "        return\n",
    "\n",
    "    total_toxicidade = 0\n",
    "    comentarios_odiosos = 0\n",
    "    comentarios_analisados = 0\n",
    "    \n",
    "    # NOVO: Lista para armazenar os coment√°rios classificados como √≥dio\n",
    "    comentarios_odiosos_lista = []\n",
    "\n",
    "    post_popular.comments.replace_more(limit=0)\n",
    "\n",
    "    for comment in post_popular.comments.list():\n",
    "        if comentarios_analisados >= limite_comentarios:\n",
    "            break\n",
    "        \n",
    "        texto_comentario = comment.body\n",
    "        \n",
    "        if not texto_comentario or texto_comentario in ['[deleted]', '[removed]']:\n",
    "            continue\n",
    "\n",
    "        resultado = avaliar_toxicidade(texto_comentario)\n",
    "        total_toxicidade += resultado[\"nivel_toxicidade\"]\n",
    "        \n",
    "        if resultado[\"eh_odio\"]:\n",
    "            comentarios_odiosos += 1\n",
    "            # NOVO: Adiciona o texto do coment√°rio √† lista\n",
    "            comentarios_odiosos_lista.append(texto_comentario)\n",
    "        \n",
    "        comentarios_analisados += 1\n",
    "\n",
    "    media_toxicidade = (total_toxicidade / comentarios_analisados) if comentarios_analisados > 0 else 0\n",
    "    \n",
    "    print(\"\\n--- Relat√≥rio Final da An√°lise ---\")\n",
    "    print(f\"  - Subreddit analisado: r/{subreddit_alvo}\")\n",
    "    print(f\"  - Post: '{post_popular.title[:60]}...'\")\n",
    "    print(f\"  - Coment√°rios analisados: {comentarios_analisados}\")\n",
    "    print(f\"  - Coment√°rios classificados como discurso de √≥dio: {comentarios_odiosos}\")\n",
    "    print(f\"  - N√≠vel m√©dio de toxicidade nos coment√°rios: {media_toxicidade:.2%}\")\n",
    "\n",
    "    # NOVO: Loop para imprimir os coment√°rios ofensivos encontrados\n",
    "    print(\"\\n\" + \"=\"*50) # Adiciona uma linha separadora\n",
    "\n",
    "    if comentarios_odiosos_lista:\n",
    "        print(\"\\n--- Coment√°rios Classificados como Discurso de √ìdio ---\")\n",
    "        for i, comentario in enumerate(comentarios_odiosos_lista, 1):\n",
    "            print(f\"{i}. {comentario}\\n---\") # Adiciona um separador entre os coment√°rios\n",
    "    else:\n",
    "        print(\"\\nNenhum coment√°rio foi classificado como discurso de √≥dio nesta amostra.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663023fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dados do usu√°rio:  Low-Stay-5562\n",
      "Analisando at√© 100 coment√°rios mais recentes...\n",
      "Analisados 10 coment√°rios...\n",
      "Analisados 20 coment√°rios...\n",
      "Analisados 30 coment√°rios...\n",
      "Analisados 40 coment√°rios...\n",
      "Analisados 50 coment√°rios...\n",
      "Analisados 60 coment√°rios...\n",
      "Analisados 70 coment√°rios...\n",
      "Analisados 80 coment√°rios...\n",
      "Analisados 90 coment√°rios...\n",
      "Analisados 100 coment√°rios...\n",
      "\n",
      "================================================================================\n",
      " RELAT√ìRIO DE AN√ÅLISE DE TOXICIDADE - USU√ÅRIO: u/ Low-Stay-5562\n",
      "================================================================================\n",
      "\n",
      "üü° CLASSIFICA√á√ÉO: MODERADAMENTE T√ìXICO\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " RESUMO ESTAT√çSTICO:\n",
      "  ‚Ä¢ Coment√°rios analisados: 100\n",
      "  ‚Ä¢ Coment√°rios ofensivos: 41\n",
      "  ‚Ä¢ Percentual de toxicidade: 41.00%\n",
      "  ‚Ä¢ N√≠vel m√©dio de toxicidade: 0.50\n",
      "  ‚Ä¢ Karma m√©dio por coment√°rio: 12.8\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " INFORMA√á√ïES DO PERFIL:\n",
      "  ‚Ä¢ Conta criada em: 2022-01-18\n",
      "  ‚Ä¢ Dias desde cria√ß√£o: 1320\n",
      "  ‚Ä¢ Karma de coment√°rios: 4,998\n",
      "  ‚Ä¢ Karma de posts: 196\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " ATIVIDADE POR SUBREDDIT (Top 5):\n",
      "  1. r/brasil: 57 coment√°rios\n",
      "  2. r/maconha: 7 coment√°rios\n",
      "  3. r/antitrampo: 6 coment√°rios\n",
      "  4. r/Patagonia: 5 coment√°rios\n",
      "  5. r/Livros: 4 coment√°rios\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " COMENT√ÅRIOS MAIS T√ìXICOS:\n",
      "\n",
      "  1. Toxicidade: 0.94 | r/brasil\n",
      "     \"Fdp t√° inchado de cacha√ßa e vem falar uma asneira dessa. Que gente maldita que elegeu esse maldito!\"\n",
      "     URL: https://reddit.com/r/brasil/comments/1migk50/senador_magno_malta_afirma_que_moraes_descumpre_a/n73tqly/\n",
      "\n",
      "  2. Toxicidade: 0.93 | r/antitrampo\n",
      "     \"Galera gosta de passar vergonha com essas historinhas merda\"\n",
      "     URL: https://reddit.com/r/antitrampo/comments/1mmsbd9/ai_linkedin/n87bd8p/\n",
      "\n",
      "  3. Toxicidade: 0.93 | r/brasil\n",
      "     \"Povo da direita √© tudo covarde e arreg√£o mesmo. Fazem um monte de merda e depois metem um atestado. \n",
      "\n",
      "Bando de covardes!\"\n",
      "     URL: https://reddit.com/r/brasil/comments/1mvzgcw/zambelli_tem_adoecimentos_psiqui√°tricos_graves/n9u2zdz/\n",
      "\n",
      " PER√çODO ANALISADO: 2025-07-31 at√© 2025-08-31\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import joblib\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "#TESTAR COM PERFIS = FAUSEN, No-Job-193, Low-Stay-5562, Madrugada123,\n",
    "\n",
    "\n",
    "def analisar_perfil_usuario(username, reddit, model, vectorizer, limite=100):\n",
    "    \"\"\"\n",
    "    Analisa o perfil de um usu√°rio do Reddit baseado em seus √∫ltimos coment√°rios\n",
    "    \n",
    "    Args:\n",
    "        username (str): Nome do usu√°rio do Reddit (sem u/) - Unica coisa que precisa preencher de vdd\n",
    "        reddit: Inst√¢ncia do PRAW\n",
    "        model: Modelo treinado de classifica√ß√£o\n",
    "        vectorizer: Vetorizador TF-IDF treinado\n",
    "        limite (int): N√∫mero m√°ximo de coment√°rios para analisar\n",
    "    \n",
    "    Returns:\n",
    "        dict: An√°lise completa do perfil do usu√°rio\n",
    "    \"\"\"\n",
    "    \n",
    "    def avaliar_toxicidade_local(comentario):\n",
    "        comentario_processado = comentario.lower()\n",
    "        comentario_vect = vectorizer.transform([comentario_processado])\n",
    "        predicao = model.predict(comentario_vect)\n",
    "        probabilidades = model.predict_proba(comentario_vect)\n",
    "        prob_odio = probabilidades[0][1]\n",
    "        \n",
    "        return {\n",
    "            \"odio\": predicao[0] == 1,\n",
    "            \"nivel_toxicidade\": prob_odio\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        print(f\"Buscando dados do usu√°rio: {username}\")\n",
    "        user = reddit.redditor(username)\n",
    "        \n",
    "        # Verifica se o usu√°rio existe\n",
    "        try:\n",
    "            user_created = user.created_utc\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'erro': f'Usu√°rio {username} n√£o encontrado ou perfil suspenso',\n",
    "                'detalhes': str(e)\n",
    "            }\n",
    "        \n",
    "        comentarios_analisados = 0\n",
    "        total_toxicidade = 0\n",
    "        comentarios_odiosos = 0\n",
    "        historico_comentarios = []\n",
    "        subreddits_atividade = []\n",
    "        comentarios_por_dia = {}\n",
    "        \n",
    "        print(f\"Analisando at√© {limite} coment√°rios mais recentes...\")\n",
    "        \n",
    "        # Busca os coment√°rios do usu√°rio\n",
    "        try:\n",
    "            for comment in user.comments.new(limit=limite):\n",
    "                if comentarios_analisados >= limite:\n",
    "                    break\n",
    "                \n",
    "                # Pula coment√°rios deletados/removidos\n",
    "                if not comment.body or comment.body in ['[deleted]', '[removed]']:\n",
    "                    continue\n",
    "                \n",
    "                # Analisa a toxicidade do coment√°rio\n",
    "                resultado = avaliar_toxicidade_local(comment.body)\n",
    "                total_toxicidade += resultado[\"nivel_toxicidade\"]\n",
    "                \n",
    "                if resultado[\"odio\"]:\n",
    "                    comentarios_odiosos += 1\n",
    "                \n",
    "                # Converte timestamp para data leg√≠vel\n",
    "                data_comentario = datetime.fromtimestamp(comment.created_utc, tz=timezone.utc)\n",
    "                data_str = data_comentario.strftime('%Y-%m-%d')\n",
    "                \n",
    "                # Registra atividade por dia\n",
    "                if data_str in comentarios_por_dia:\n",
    "                    comentarios_por_dia[data_str] += 1\n",
    "                else:\n",
    "                    comentarios_por_dia[data_str] = 1\n",
    "                \n",
    "                # Registra subreddit de atividade\n",
    "                subreddits_atividade.append(comment.subreddit.display_name)\n",
    "                \n",
    "                # Salva detalhes do coment√°rio\n",
    "                historico_comentarios.append({\n",
    "                    'texto': comment.body[:200] + \"...\" if len(comment.body) > 200 else comment.body,\n",
    "                    'texto_completo': comment.body,\n",
    "                    'toxicidade': resultado[\"nivel_toxicidade\"],\n",
    "                    'odio': resultado[\"odio\"],\n",
    "                    'subreddit': comment.subreddit.display_name,\n",
    "                    'data': data_str,\n",
    "                    'timestamp': comment.created_utc,\n",
    "                    'score': comment.score,\n",
    "                    'url': f\"https://reddit.com{comment.permalink}\"\n",
    "                })\n",
    "                \n",
    "                comentarios_analisados += 1\n",
    "                \n",
    "                # Pequena pausa para n√£o sobrecarregar a API\n",
    "                if comentarios_analisados % 10 == 0:\n",
    "                    print(f\"Analisados {comentarios_analisados} coment√°rios...\")\n",
    "                    time.sleep(0.1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao buscar coment√°rios: {e}\")\n",
    "            if comentarios_analisados == 0:\n",
    "                return {\n",
    "                    'erro': f'N√£o foi poss√≠vel acessar os coment√°rios de {username}',\n",
    "                    'detalhes': 'Perfil pode ser privado ou sem coment√°rios p√∫blicos'\n",
    "                }\n",
    "        \n",
    "        if comentarios_analisados == 0:\n",
    "            return {\n",
    "                'erro': f'Usu√°rio {username} n√£o possui coment√°rios p√∫blicos para analisar'\n",
    "            }\n",
    "        \n",
    "        # Calcula estat√≠sticas\n",
    "        nivel_medio_toxicidade = total_toxicidade / comentarios_analisados\n",
    "        percentual_odioso = (comentarios_odiosos / comentarios_analisados) * 100\n",
    "        \n",
    "        # Analisa subreddits mais ativos\n",
    "        subreddits_counter = Counter(subreddits_atividade)\n",
    "        top_subreddits = subreddits_counter.most_common(10)\n",
    "        \n",
    "        # Encontra os coment√°rios mais t√≥xicos\n",
    "        comentarios_ordenados = sorted(historico_comentarios, \n",
    "                                     key=lambda x: x['toxicidade'], \n",
    "                                     reverse=True)\n",
    "        comentarios_mais_toxicos = comentarios_ordenados[:5]\n",
    "        \n",
    "        # Calcula karma m√©dio dos coment√°rios\n",
    "        scores = [c['score'] for c in historico_comentarios if c['score'] is not None]\n",
    "        karma_medio = sum(scores) / len(scores) if scores else 0\n",
    "        \n",
    "        # Data de cria√ß√£o da conta\n",
    "        data_criacao = datetime.fromtimestamp(user_created, tz=timezone.utc)\n",
    "        dias_desde_criacao = (datetime.now(timezone.utc) - data_criacao).days\n",
    "        \n",
    "        # Classifica o usu√°rio\n",
    "        if percentual_odioso >= 50:\n",
    "            classificacao = \"MUITO T√ìXICO\"\n",
    "            cor_classificacao = \"üî¥\"\n",
    "        elif percentual_odioso >= 30:\n",
    "            classificacao = \"MODERADAMENTE T√ìXICO\"\n",
    "            cor_classificacao = \"üü°\"\n",
    "        elif percentual_odioso >= 10:\n",
    "            classificacao = \"LEVEMENTE T√ìXICO\"\n",
    "            cor_classificacao = \"üü†\"\n",
    "        else:\n",
    "            classificacao = \"N√ÉO T√ìXICO\"\n",
    "            cor_classificacao = \"üü¢\"\n",
    "        \n",
    "        resultado_final = {\n",
    "            'username': username,\n",
    "            'classificacao': classificacao,\n",
    "            'cor_classificacao': cor_classificacao,\n",
    "            'resumo': {\n",
    "                'total_comentarios_analisados': comentarios_analisados,\n",
    "                'comentarios_odiosos': comentarios_odiosos,\n",
    "                'percentual_odioso': round(percentual_odioso, 2),\n",
    "                'nivel_medio_toxicidade': round(nivel_medio_toxicidade, 4),\n",
    "                'karma_medio_comentarios': round(karma_medio, 2)\n",
    "            },\n",
    "            'perfil': {\n",
    "                'data_criacao_conta': data_criacao.strftime('%Y-%m-%d'),\n",
    "                'dias_desde_criacao': dias_desde_criacao,\n",
    "                'karma_comentarios': user.comment_karma,\n",
    "                'karma_posts': user.link_karma\n",
    "            },\n",
    "            'atividade': {\n",
    "                'subreddits_mais_ativos': top_subreddits,\n",
    "                'comentarios_por_dia': comentarios_por_dia,\n",
    "                'periodo_analisado': f\"{min(comentarios_por_dia.keys())} at√© {max(comentarios_por_dia.keys())}\" if comentarios_por_dia else \"N/A\"\n",
    "            },\n",
    "            'comentarios_mais_toxicos': comentarios_mais_toxicos,\n",
    "            'historico_completo': historico_comentarios\n",
    "        }\n",
    "        \n",
    "        return resultado_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'erro': f'Erro inesperado ao analisar {username}',\n",
    "            'detalhes': str(e)\n",
    "        }\n",
    "\n",
    "def imprimir_relatorio_usuario(resultado):\n",
    "    \n",
    "    if 'erro' in resultado:\n",
    "        print(f\"!!!! ERRO !!!!: {resultado['erro']}\")\n",
    "        if 'detalhes' in resultado:\n",
    "            print(f\"Detalhes: {resultado['detalhes']}\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" RELAT√ìRIO DE AN√ÅLISE DE TOXICIDADE - USU√ÅRIO: u/{resultado['username']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    \n",
    "    print(f\"\\n{resultado['cor_classificacao']} CLASSIFICA√á√ÉO: {resultado['classificacao']}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n RESUMO ESTAT√çSTICO:\")\n",
    "    print(f\"  ‚Ä¢ Coment√°rios analisados: {resultado['resumo']['total_comentarios_analisados']}\")\n",
    "    print(f\"  ‚Ä¢ Coment√°rios ofensivos: {resultado['resumo']['comentarios_odiosos']}\")\n",
    "    print(f\"  ‚Ä¢ Percentual de toxicidade: {resultado['resumo']['percentual_odioso']:.2f}%\")\n",
    "    print(f\"  ‚Ä¢ N√≠vel m√©dio de toxicidade: {resultado['resumo']['nivel_medio_toxicidade']:.2f}\")\n",
    "    print(f\"  ‚Ä¢ Karma m√©dio por coment√°rio: {resultado['resumo']['karma_medio_comentarios']:.1f}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(f\"\\n INFORMA√á√ïES DO PERFIL:\")\n",
    "    print(f\"  ‚Ä¢ Conta criada em: {resultado['perfil']['data_criacao_conta']}\")\n",
    "    print(f\"  ‚Ä¢ Dias desde cria√ß√£o: {resultado['perfil']['dias_desde_criacao']}\")\n",
    "    print(f\"  ‚Ä¢ Karma de coment√°rios: {resultado['perfil']['karma_comentarios']:,}\")\n",
    "    print(f\"  ‚Ä¢ Karma de posts: {resultado['perfil']['karma_posts']:,}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n ATIVIDADE POR SUBREDDIT (Top 5):\")\n",
    "    for i, (subreddit, count) in enumerate(resultado['atividade']['subreddits_mais_ativos'][:5], 1):\n",
    "        print(f\"  {i}. r/{subreddit}: {count} coment√°rios\")\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    print(f\"\\n COMENT√ÅRIOS MAIS T√ìXICOS:\")\n",
    "    for i, comentario in enumerate(resultado['comentarios_mais_toxicos'][:3], 1):\n",
    "        print(f\"\\n  {i}. Toxicidade: {comentario['toxicidade']:.2f} | r/{comentario['subreddit']}\")\n",
    "        print(f\"     \\\"{comentario['texto']}\\\"\")\n",
    "        print(f\"     URL: {comentario['url']}\")\n",
    "    \n",
    "    print(f\"\\n PER√çODO ANALISADO: {resultado['atividade']['periodo_analisado']}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Exemplo de uso\n",
    "def exemplo_uso():\n",
    "    \"\"\"\n",
    "    Exemplo de como usar as fun√ß√µes\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    load_dotenv()\n",
    "    \n",
    "    # Configura√ß√£o do Reddit\n",
    "    CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "    CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "    USER_AGENT = os.getenv(\"USER_AGENT\")\n",
    "    \n",
    "    # Carrega o modelo\n",
    "    try:\n",
    "        model = joblib.load('modelo_odio.joblib')\n",
    "        vectorizer = joblib.load('vetorizador_odio.joblib')\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERRO: Modelos n√£o encontrados. Execute o treinamento primeiro.\")\n",
    "        return\n",
    "    \n",
    "    # Conecta ao Reddit\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT,\n",
    "        check_for_async=False\n",
    "    )\n",
    "    \n",
    "    # Analisa um usu√°rio (substitua pelo username desejado)\n",
    "    username = input(\"Digite o username para analisar (sem u/): \")\n",
    "    \n",
    "    resultado = analisar_perfil_usuario(username, reddit, model, vectorizer, limite=100)\n",
    "    imprimir_relatorio_usuario(resultado)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exemplo_uso()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
